# üë®‚Äçüè´ Gu√≠a del Profesor - Lab 01: Fundamentos de Big Data

## Resumen Ejecutivo

**Duraci√≥n**: 90-120 minutos
**Nivel**: Principiante (sin experiencia previa en Big Data)
**M√≥dulo AWS Academy**: M√≥dulo 3 - Data Characteristics

---

## üöÄ Comandos R√°pidos para Levantar el Ambiente

### Antes de la Clase (Preparaci√≥n)

```bash
# 1. Navegar al directorio del proyecto
cd ~/Documents/big-data-uag-2026

# 2. Construir las im√°genes Docker (solo primera vez, ~5-10 min)
docker compose -f infrastructure/docker-compose.spark.yml build

# 3. Verificar que no hay conflictos de puertos
lsof -i :8888  # Jupyter
lsof -i :8080  # Spark Master
lsof -i :8081  # Spark Worker
```

### Durante la Clase

```bash
# Levantar el cluster completo
docker compose -f infrastructure/docker-compose.spark.yml up -d

# Verificar que todo est√° corriendo
docker compose -f infrastructure/docker-compose.spark.yml ps

# Ver los logs si hay problemas
docker compose -f infrastructure/docker-compose.spark.yml logs -f
```

### Despu√©s de la Clase

```bash
# Detener el cluster (preserva vol√∫menes)
docker compose -f infrastructure/docker-compose.spark.yml stop

# O detener y limpiar completamente
docker compose -f infrastructure/docker-compose.spark.yml down
```

---

## üåê URLs para Compartir con Alumnos

| Servicio | URL | Descripci√≥n |
|----------|-----|-------------|
| Jupyter Lab | http://localhost:8888 | Notebooks (sin password) |
| Spark Master UI | http://localhost:8080 | Dashboard del cluster |
| Spark Worker UI | http://localhost:8081 | Estado del worker |
| Spark App UI | http://localhost:4040 | Jobs activos |

---

## üìã Checklist Pre-Clase

- [ ] Docker Desktop instalado y corriendo
- [ ] Al menos 4GB de RAM disponible
- [ ] Puertos 8888, 8080, 8081, 4040 libres
- [ ] Im√°genes Docker construidas (`docker compose build`)
- [ ] Cluster probado localmente
- [ ] Proyector/pantalla configurado

---

## üéØ Objetivos de Aprendizaje

Al finalizar, los alumnos ser√°n capaces de:

1. **Explicar** qu√© es Big Data y por qu√© es importante
2. **Describir** las 5 Vs con ejemplos del mundo real
3. **Diferenciar** entre datos estructurados, semi-estructurados y no estructurados
4. **Crear** una SparkSession y cargar datos
5. **Realizar** operaciones b√°sicas de exploraci√≥n (select, filter, groupBy)

---

## üìñ Plan de Clase Sugerido

### Parte 1: Introducci√≥n Te√≥rica (30 min)

1. **¬øQu√© es Big Data?** (10 min)
   - Mostrar estad√≠sticas impactantes (datos generados por d√≠a)
   - Analog√≠a de la biblioteca
   - Preguntar: "¬øQu√© apps usan Big Data?"

2. **Las 5 Vs** (15 min)
   - Explicar cada V con ejemplos
   - Conectar con el dataset de taxis de NYC
   - Ejercicio oral: identificar las Vs en Netflix/Uber

3. **Tipos de Datos** (5 min)
   - Estructurados vs Semi-estructurados vs No estructurados
   - Porcentajes del mundo real (80% no estructurados)

### Parte 2: Pr√°ctica Guiada (45 min)

1. **Setup del Ambiente** (10 min)
   - Abrir Jupyter Lab
   - Navegar al notebook
   - Ejecutar celda de configuraci√≥n

2. **Crear SparkSession** (10 min)
   - Explicar qu√© es SparkSession
   - Ejecutar la celda
   - Mostrar Spark UI (localhost:8080)

3. **Exploraci√≥n de Datos** (25 min)
   - Generar datos de muestra
   - show(), describe()
   - select(), filter(), groupBy()
   - Visualizaci√≥n b√°sica

### Parte 3: Ejercicios Individuales (30 min)

1. **Ejercicio 1**: An√°lisis de pasajeros (10 min)
2. **Ejercicio 2**: Viajes cortos/largos (10 min)
3. **Ejercicio 3**: Distancia calculada (10 min)

### Cierre (10 min)

- Resumen de conceptos clave
- Conexi√≥n con AWS (EMR, Glue)
- Preguntas y respuestas
- Asignar lectura para pr√≥xima clase

---

## üí° Tips Pedag√≥gicos

### Para Mantener la Atenci√≥n

- Usar analog√≠as del mundo real constantemente
- Hacer preguntas interactivas: "¬øCu√°ntos datos genera Spotify?"
- Mostrar la Spark UI para visualizar el procesamiento
- Comparar tiempos: Pandas vs Spark (cuando hay m√°s datos)

### Errores Comunes de Alumnos

| Error | Soluci√≥n |
|-------|----------|
| "Connection refused" | Verificar que Docker est√° corriendo |
| "SparkSession already exists" | Reiniciar el kernel del notebook |
| Celda no ejecuta | Verificar que ejecutaron celdas anteriores |
| OutOfMemoryError | Reducir tama√±o de datos o aumentar memoria |

### Preguntas Frecuentes

**Q: ¬øPor qu√© no usamos pandas directamente?**
A: Pandas carga todo en memoria de una m√°quina. Spark distribuye los datos entre m√∫ltiples m√°quinas, permitiendo procesar terabytes.

**Q: ¬øCu√°ndo debo usar Big Data?**
A: Cuando tus datos no caben en memoria de una sola m√°quina, o cuando necesitas procesar en tiempo real.

**Q: ¬øQu√© diferencia hay entre esto y AWS?**
A: Usamos las mismas tecnolog√≠as (Spark), pero en local. AWS provee la infraestructura para escalar a producci√≥n.

---

## üìä Evaluaci√≥n Sugerida

### Criterios de Evaluaci√≥n por Ejercicio

| Ejercicio | Puntos | Criterios |
|-----------|--------|-----------|
| Ejercicio 1 | 30 | groupBy correcto, ordenamiento, porcentaje calculado |
| Ejercicio 2 | 30 | Filtros correctos, conteo, ejemplos mostrados |
| Ejercicio 3 | 40 | Nueva columna creada, f√≥rmula correcta, agregaci√≥n |

### Preguntas de Reflexi√≥n (Tarea)

1. ¬øCu√°l de las 5 Vs consideras m√°s importante y por qu√©?
2. Describe 3 ejemplos de datos no estructurados en tu vida diaria
3. ¬øQu√© servicio de AWS usar√≠as para procesar 10TB de logs?

---

## üîó Recursos Adicionales

### Para Profundizar

- [Apache Spark Documentation](https://spark.apache.org/docs/latest/)
- [AWS Big Data Blog](https://aws.amazon.com/blogs/big-data/)
- [M√≥dulo 3 AWS Academy](https://awsacademy.instructure.com/)

### Videos Recomendados

- "What is Big Data?" - Simplilearn (10 min)
- "Apache Spark in 5 minutes" - Databricks (5 min)

---

## ‚ö†Ô∏è Soluci√≥n de Problemas en Clase

### Si Docker no inicia

```bash
# Reiniciar Docker Desktop
# O desde terminal:
killall Docker && open -a Docker
```

### Si Jupyter no responde

```bash
# Reiniciar solo el contenedor de Jupyter
docker restart jupyter-spark
```

### Si Spark no conecta

```bash
# Verificar que spark-master est√° corriendo
docker logs spark-master

# Reiniciar el cluster completo
docker compose -f infrastructure/docker-compose.spark.yml restart
```

### Si un alumno no puede acceder

1. Verificar que est√° en la misma red (si es remoto)
2. Verificar firewall/antivirus
3. Usar `docker-compose logs` para diagnosticar

---

## üìù Notas del Laboratorio

**Cambios realizados**:
- Fecha: 2026-01-28
- Versi√≥n: 1.0

**Pr√≥xima actualizaci√≥n**:
- Agregar m√°s visualizaciones
- Conectar con dataset real de Kaggle
- Agregar ejercicio de streaming preview
